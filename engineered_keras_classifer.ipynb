{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "# Implementing Callbacks to save various check points of our keras model; can be used to terminate model prematurely to also prevent overfitting\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "# for single predictions\n",
    "from keras.preprocessing import image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Appzone-MLG\\Anaconda3\\envs\\chest_xray_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# initializing the classfier\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (350, 350, 1), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "classifier.add(Dense(activation = 'relu', units = 128))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(activation = 'relu', units = 64))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(activation = 'relu', units = 64))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(activation = 'relu', units = 64))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(activation = 'relu', units = 64))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(activation = 'sigmoid', units = 14))\n",
    "\n",
    "classifier.compile(optimizer = 'adam',\n",
    "                   loss ='binary_crossentropy',\n",
    "                   metrics = ['accuracy']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 348, 348, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 174, 174, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 174, 174, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 172, 172, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 84, 84, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3276928   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 3,382,926\n",
      "Trainable params: 3,382,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display all the columns of the dataframe in the notebook\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file \n",
    "# Here we will be using a subset of the original dataset\n",
    "\n",
    "train = pd.read_csv('CheXpert-v1.0-small/train_data.csv', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>no_finding</th>\n",
       "      <th>enlarged_cardiomediastinum</th>\n",
       "      <th>cardiomegaly</th>\n",
       "      <th>lung_opacity</th>\n",
       "      <th>lung_lesion</th>\n",
       "      <th>edema</th>\n",
       "      <th>consolidation</th>\n",
       "      <th>pneumonia</th>\n",
       "      <th>atelectasis</th>\n",
       "      <th>pneumothorax</th>\n",
       "      <th>pleural_effusion</th>\n",
       "      <th>pleural_other</th>\n",
       "      <th>fracture</th>\n",
       "      <th>support_devices</th>\n",
       "      <th>no_of_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  no_finding  \\\n",
       "0  CheXpert-v1.0-small/train/patient00001/study1/...         1.0   \n",
       "1  CheXpert-v1.0-small/train/patient00002/study2/...         0.0   \n",
       "2  CheXpert-v1.0-small/train/patient00002/study1/...         0.0   \n",
       "3  CheXpert-v1.0-small/train/patient00002/study1/...         0.0   \n",
       "4  CheXpert-v1.0-small/train/patient00003/study1/...         0.0   \n",
       "\n",
       "   enlarged_cardiomediastinum  cardiomegaly  lung_opacity  lung_lesion  edema  \\\n",
       "0                         0.0           0.0           0.0          0.0    0.0   \n",
       "1                         0.0           0.0           1.0          0.0    0.0   \n",
       "2                         0.0           0.0           1.0          0.0    0.0   \n",
       "3                         0.0           0.0           1.0          0.0    0.0   \n",
       "4                         0.0           0.0           0.0          0.0    1.0   \n",
       "\n",
       "   consolidation  pneumonia  atelectasis  pneumothorax  pleural_effusion  \\\n",
       "0            0.0        0.0          0.0           0.0               0.0   \n",
       "1            0.0        0.0          0.0           0.0               0.0   \n",
       "2            0.0        0.0          0.0           0.0               0.0   \n",
       "3            0.0        0.0          0.0           0.0               0.0   \n",
       "4            0.0        0.0          0.0           0.0               0.0   \n",
       "\n",
       "   pleural_other  fracture  support_devices  no_of_labels  \n",
       "0            0.0       0.0              1.0           1.0  \n",
       "1            0.0       1.0              0.0           2.0  \n",
       "2            0.0       1.0              0.0           2.0  \n",
       "3            0.0       1.0              0.0           2.0  \n",
       "4            0.0       0.0              0.0           1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 430.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading and preprocessing \n",
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img(''+train['path'][i]+'', target_size=(350, 350, 1), color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(X[0], cmap='gray')\n",
    "# plt.imshow(X[2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the Onehot encoded label\n",
    "y = np.array(train.drop(['path', 'no_of_labels'],axis=1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "900/900 [==============================] - 11s 12ms/step - loss: 0.5054 - acc: 0.7754 - val_loss: 0.5448 - val_acc: 0.8200\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.4168 - acc: 0.8240 - val_loss: 0.5293 - val_acc: 0.8200\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.4063 - acc: 0.8270 - val_loss: 0.4980 - val_acc: 0.8157\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.4014 - acc: 0.8325 - val_loss: 0.4658 - val_acc: 0.8193\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3964 - acc: 0.8275 - val_loss: 0.4204 - val_acc: 0.8093\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3900 - acc: 0.8314 - val_loss: 0.4140 - val_acc: 0.8157\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3867 - acc: 0.8310 - val_loss: 0.3944 - val_acc: 0.8157\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3832 - acc: 0.8325 - val_loss: 0.3893 - val_acc: 0.8157\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3852 - acc: 0.8359 - val_loss: 0.3899 - val_acc: 0.8157\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3811 - acc: 0.8347 - val_loss: 0.3970 - val_acc: 0.8157\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3830 - acc: 0.8353 - val_loss: 0.3858 - val_acc: 0.8157\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3764 - acc: 0.8370 - val_loss: 0.3888 - val_acc: 0.8157\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3773 - acc: 0.8366 - val_loss: 0.3904 - val_acc: 0.8136\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3737 - acc: 0.8392 - val_loss: 0.3858 - val_acc: 0.8250\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3690 - acc: 0.8429 - val_loss: 0.3773 - val_acc: 0.8250\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3650 - acc: 0.8479 - val_loss: 0.3762 - val_acc: 0.8271\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3622 - acc: 0.8511 - val_loss: 0.3723 - val_acc: 0.8393\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3547 - acc: 0.8538 - val_loss: 0.3678 - val_acc: 0.8379\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3555 - acc: 0.8524 - val_loss: 0.3666 - val_acc: 0.8321\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3518 - acc: 0.8552 - val_loss: 0.3658 - val_acc: 0.8421\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3463 - acc: 0.8580 - val_loss: 0.3689 - val_acc: 0.8429\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3468 - acc: 0.8586 - val_loss: 0.3626 - val_acc: 0.8436\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3375 - acc: 0.8606 - val_loss: 0.3563 - val_acc: 0.8450\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3395 - acc: 0.8608 - val_loss: 0.3624 - val_acc: 0.8407\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3309 - acc: 0.8605 - val_loss: 0.3672 - val_acc: 0.8443\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3264 - acc: 0.8654 - val_loss: 0.3666 - val_acc: 0.8450\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3307 - acc: 0.8628 - val_loss: 0.3639 - val_acc: 0.8421\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3202 - acc: 0.8629 - val_loss: 0.3572 - val_acc: 0.8379\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3116 - acc: 0.8721 - val_loss: 0.3523 - val_acc: 0.8393\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.3078 - acc: 0.8710 - val_loss: 0.3608 - val_acc: 0.8414\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2954 - acc: 0.8788 - val_loss: 0.3624 - val_acc: 0.8386\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2958 - acc: 0.8758 - val_loss: 0.3603 - val_acc: 0.8450\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2814 - acc: 0.8821 - val_loss: 0.3638 - val_acc: 0.8429\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2779 - acc: 0.8848 - val_loss: 0.3695 - val_acc: 0.8457\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2739 - acc: 0.8843 - val_loss: 0.3684 - val_acc: 0.8479\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2692 - acc: 0.8890 - val_loss: 0.3748 - val_acc: 0.8471\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2671 - acc: 0.8848 - val_loss: 0.3667 - val_acc: 0.8493\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2600 - acc: 0.8908 - val_loss: 0.3789 - val_acc: 0.8514\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2470 - acc: 0.8976 - val_loss: 0.3847 - val_acc: 0.8493\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2432 - acc: 0.8971 - val_loss: 0.3918 - val_acc: 0.8457\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2484 - acc: 0.8957 - val_loss: 0.3934 - val_acc: 0.8407\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2408 - acc: 0.8971 - val_loss: 0.3890 - val_acc: 0.8400\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2323 - acc: 0.9037 - val_loss: 0.3888 - val_acc: 0.8443\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2296 - acc: 0.9043 - val_loss: 0.3865 - val_acc: 0.8407\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2216 - acc: 0.9080 - val_loss: 0.4057 - val_acc: 0.8386\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2252 - acc: 0.9056 - val_loss: 0.3932 - val_acc: 0.8414\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2294 - acc: 0.9044 - val_loss: 0.4011 - val_acc: 0.8379\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2178 - acc: 0.9067 - val_loss: 0.3956 - val_acc: 0.8450\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2093 - acc: 0.9104 - val_loss: 0.3965 - val_acc: 0.8450\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 6s 6ms/step - loss: 0.2086 - acc: 0.9132 - val_loss: 0.4020 - val_acc: 0.8379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5bde0df28>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using image generators\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 validated image filenames.\n",
      "Found 234 validated image filenames.\n",
      "Epoch 1/15\n",
      "200/200 [==============================] - 77s 387ms/step - loss: 0.3311 - acc: 0.8591 - val_loss: 0.4457 - val_acc: 0.8068\n",
      "Epoch 2/15\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.3295 - acc: 0.8607 - val_loss: 0.4476 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00002: val_loss improved from inf to 0.44764, saving model to models/weights-improvement-02-0.45-0.81.hdf5\n",
      "Epoch 3/15\n",
      "200/200 [==============================] - 74s 369ms/step - loss: 0.3278 - acc: 0.8609 - val_loss: 0.4454 - val_acc: 0.8080\n",
      "Epoch 4/15\n",
      "200/200 [==============================] - 77s 384ms/step - loss: 0.3265 - acc: 0.8621 - val_loss: 0.4465 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44764 to 0.44653, saving model to models/weights-improvement-04-0.45-0.81.hdf5\n",
      "Epoch 5/15\n",
      "200/200 [==============================] - 75s 375ms/step - loss: 0.3232 - acc: 0.8634 - val_loss: 0.4512 - val_acc: 0.8114\n",
      "Epoch 6/15\n",
      "200/200 [==============================] - 76s 378ms/step - loss: 0.3223 - acc: 0.8634 - val_loss: 0.4532 - val_acc: 0.8095\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.44653\n",
      "Epoch 7/15\n",
      "200/200 [==============================] - 75s 374ms/step - loss: 0.3221 - acc: 0.8630 - val_loss: 0.4468 - val_acc: 0.8089\n",
      "Epoch 8/15\n",
      "200/200 [==============================] - 77s 386ms/step - loss: 0.3196 - acc: 0.8642 - val_loss: 0.4492 - val_acc: 0.8129\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44653\n",
      "Epoch 9/15\n",
      "200/200 [==============================] - 77s 384ms/step - loss: 0.3169 - acc: 0.8646 - val_loss: 0.4444 - val_acc: 0.8165\n",
      "Epoch 10/15\n",
      "200/200 [==============================] - 76s 378ms/step - loss: 0.3185 - acc: 0.8655 - val_loss: 0.4467 - val_acc: 0.8135\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44653\n",
      "Epoch 11/15\n",
      "200/200 [==============================] - 74s 372ms/step - loss: 0.3153 - acc: 0.8676 - val_loss: 0.4476 - val_acc: 0.8141\n",
      "Epoch 12/15\n",
      "200/200 [==============================] - 76s 381ms/step - loss: 0.3136 - acc: 0.8673 - val_loss: 0.4458 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44653 to 0.44581, saving model to models/weights-improvement-12-0.45-0.81.hdf5\n",
      "Epoch 13/15\n",
      "200/200 [==============================] - 78s 392ms/step - loss: 0.3134 - acc: 0.8680 - val_loss: 0.4495 - val_acc: 0.8147\n",
      "Epoch 14/15\n",
      "200/200 [==============================] - 71s 357ms/step - loss: 0.3122 - acc: 0.8683 - val_loss: 0.4501 - val_acc: 0.8104\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.44581\n",
      "Epoch 15/15\n",
      "200/200 [==============================] - 73s 364ms/step - loss: 0.3098 - acc: 0.8690 - val_loss: 0.4505 - val_acc: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f76bc20e10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"CheXpert-v1.0-small/train_data.csv\", nrows=6400)\n",
    "valid_df = pd.read_csv(\"CheXpert-v1.0-small/valid.csv\")\n",
    "\n",
    "tensor_log_name = f\"chest-xray-cnn-{int(time.time())}\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=None,\n",
    "        x_col=\"path\",\n",
    "        y_col=['no_finding',\n",
    "               'enlarged_cardiomediastinum',\n",
    "               'cardiomegaly',\n",
    "               'lung_opacity',\n",
    "               'lung_lesion',\n",
    "               'edema',\n",
    "               'consolidation',\n",
    "               'pneumonia',\n",
    "               'atelectasis',\n",
    "               'pneumothorax',\n",
    "               'pleural_effusion',\n",
    "               'pleural_other',\n",
    "               'fracture',\n",
    "               'support_devices'\n",
    "               ],\n",
    "        color_mode=\"grayscale\",\n",
    "        target_size=(350, 350),\n",
    "        batch_size=32,\n",
    "#         class_mode=\"multi_output\",\n",
    "        class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=None,\n",
    "        x_col=\"Path\",\n",
    "        y_col=['No Finding',\n",
    "               'Enlarged Cardiomediastinum',\n",
    "               'Cardiomegaly',\n",
    "               'Lung Opacity',\n",
    "               'Lung Lesion',\n",
    "               'Edema',\n",
    "               'Consolidation',\n",
    "               'Pneumonia',\n",
    "               'Atelectasis',\n",
    "               'Pneumothorax',\n",
    "               'Pleural Effusion',\n",
    "               'Pleural Other',\n",
    "               'Fracture',\n",
    "               'Support Devices'\n",
    "              ],\n",
    "        color_mode=\"grayscale\",\n",
    "        target_size=(350, 350),\n",
    "        batch_size=128,\n",
    "        class_mode=\"raw\")\n",
    "\n",
    "# filepath contains location for storing keras models with the lowwest loss function after every 10 epoch\n",
    "filepath=\"models/weights-improvement-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min',\n",
    "#                              save_freq=5\n",
    "                             period=2\n",
    "                            )\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = f'logs/{tensor_log_name}')\n",
    "\n",
    "classifier.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=15,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=2,\n",
    "        callbacks=[checkpoint, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single preds\n",
    "test_image = image.load_img('CheXpert-v1.0-small/valid/patient64740/study1/view1_frontal.jpg',\n",
    "                            target_size = (350, 350),\n",
    "                            color_mode= 'grayscale'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=350x350 at 0x1F5FC521EF0>\n"
     ]
    }
   ],
   "source": [
    "print(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_arr = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_arr = np.expand_dims(test_image_arr, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3841858e-07,\n",
       "        0.0000000e+00, 7.5799823e-03, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_image_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model on local storage\n",
    "\n",
    "# Save the model\n",
    "classifier.save('models/first_test_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('models/first_test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard(log_dir='./logs',\n",
    "#              histogram_freq=0,\n",
    "#              batch_size=32,\n",
    "#              write_graph=True,\n",
    "#              write_grads=False,\n",
    "#              write_images=False,\n",
    "#              embeddings_freq=0,\n",
    "#              embeddings_layer_names=None,\n",
    "#              embeddings_metadata=None,\n",
    "#              embeddings_data=None,\n",
    "#              update_freq='epoch'\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in cmd\n",
    "# tensorboard --logdir=/logs\n",
    "\n",
    "# Enter link below in browser to visit TensorBoard\n",
    "http://localhost:6006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
